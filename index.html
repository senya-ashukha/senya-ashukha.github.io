<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Senya Ashukha</title>
  
  <meta name="author" content="Senya Ashukha">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">

  <style>
    .collapsible-content {
      display: none; /* Hidden by default */
    }
    .toggle-button {
      background-color: rgba(240, 240, 240, 0.8); /* MODIFIED: Made background transparent */
      border: 1px solid #ccc;
      border-radius: 8px; /* ADDED: Rounds the corners */
      padding: 8px 16px;
      cursor: pointer;
      width: 100%;
      text-align: left;
      font-size: 1em;
      margin-top: 15px;
      margin-bottom: 15px;
      transition: background-color 0.3s; /* ADDED: Smooth transition for hover */
    }
    .toggle-button:hover {
      background-color: rgba(224, 224, 224, 0.95); /* MODIFIED: Adjusted hover color */
    }
  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <a href="images/Iso_Wallpaper_Blocks_06.jpg">
          <img style="width:100%;max-width:100%; border-radius: 15px;" alt="profile photo" src="images/Iso_Wallpaper_Blocks_06.jpg" class="hoverZoomLink">
        </a>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Arsenii Ashukha</name>
              </p>
              <p>
                <br>
                I am a Senior Research Scientist at <a href="https://www.isomorphiclabs.com/">Isomorphic Labs</a>, 
                an Alphabet subsidiary led by Demis Hassabis, where I work on deep learning models for interaction
                of drug and protein molecules. Previously I was a Research Scientist at Samsung and PhD student 
                at the <a href="https://bayesgroup.ru/">Bayesian Methods Research Group</a> under the 
                supervision of <a href="https://bayesgroup.org/people/dmitry-vetrov/">Dmitry Vetrov</a>.
                <br>
                <br>
                Selected open projects: <a href="https://github.com/advimman/lama">LaMa Inpainting (‚≠êÔ∏è9.1k)</a>, <a href="https://github.com/bayesgroup/variational-dropout-sparsifies-dnn">Variational Dropout Sparsifies DNN</a>.
                <p align=center>
                <a href="mailto:ars.ashuha@gmail.com" target="_blank">Email</a> &nbsp/&nbsp
                <a href="https://senya-ashukha.github.io/arsenii-ashukha-cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=IU-kuP8AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/senya-ashuha">GitHub</a> &nbsp/&nbsp
                <a href="https://twitter.com/senya_ashukha">Twitter</a> / üìçLondon (UK)
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%;">
              <a href="https://scholar.google.com/citations?user=IU-kuP8AAAAJ&hl=en"><img style="width:100%;max-width:100%; border-radius: 15px;" alt="profile photo" src="images/senya-ashukha.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Research</heading>
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='projects/lama_21/ezgif-7-d6037b7aa186.gif' width="160px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle" bgcolor="#ffffff">
              <a href="https://arxiv.org/abs/2109.07161">
                <papertitle>Resolution-robust Large Mask Inpainting with Fourier Convolutions</papertitle>
              </a>
              <br>
             <a href="https://scholar.google.com/citations?user=HvVrLNwAAAAJ&hl=en">Roman Suvorov</a>, <a href="https://scholar.google.com/citations?hl=en&user=pf5LuKkAAAAJ">Elizaveta Logacheva</a>, <a href="https://www.kaggle.com/heyt0ny">Anton Mashikhin</a>, <a href="https://ru.linkedin.com/in/aremizova"> Anastasia Remizova</a>, 
              <strong>Arsenii Ashukha</strong>, <a href="https://dblp.org/pid/261/3035.html">Aleksei Silvestrov</a>, <a href="https://kr.linkedin.com/in/naejin-kong-654a58ba">Naejin Kong</a>, <a href="https://in.linkedin.com/in/harshithgoka">Harshith Goka</a>, <a href="https://kr.linkedin.com/in/kiwoong-park-67b02218">Kiwoong Park</a>, <a href="https://scholar.google.com/citations?user=gYYVokYAAAAJ&hl=en">Victor Lempitsky</a>
              <br>
                <em>WACV</em>, 2022  
              <br>
                <a href="https://saic-mdal.github.io/lama-project/">project page</a> / 
                <a href="https://youtu.be/K0-eoCfk0nU">poster video (5 mins)</a> / 
                <a href="https://arxiv.org/abs/2109.07161">arXiv</a> / 
                <a href="https://github.com/saic-mdal/lama">code</a> / 
                <a href="https://senya-ashukha.github.io/projects/lama_21/paper.txt" target="_blank">bibtex</a> /
                <a href="https://youtu.be/Lg97gWXsiQ4" target="_blank">Yannic Kilcher</a> / 
                <a href="https://www.casualganpapers.com/large-masks-fourier-convolutions-inpainting/LaMa-explained.html" target="_blank">Casual GAN</a>
              <p>
              LaMa uses convolutions in the Fourier space to generalize to a high 2k resolutions, despite being trained on 256x256 images. It achieves a strong performance even in challenging scenarios, e.g. completion of periodic structures.</p>
            </td>
          </tr>
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='projects/svdo_icml17/svdo_prev.png' width="160px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle" bgcolor="#ffffff">
              <a href="http://proceedings.mlr.press/v70/molchanov17a.html">
                <papertitle>Variational Dropout Sparsifies Deep Neural Networks</papertitle>
              </a>
              <br>
              <strong>Arsenii Ashukha*</strong>,
              <a href="https://scholar.google.com/citations?user=tJ6JXRYAAAAJ&hl=en">Dmitry Molchanov*</a>,
              <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
              <br>
                <em>ICML</em>, 2017  
              <br>
               <a href="javascript:void(0)" onclick="var e = document.getElementById('contact2'); e.style.display = (e.style.display == 'block' ? 'none' : 'block');" style="color:gray"><b>retrospective‚è≥</b></a> /
                <a href="https://iclr.cc/virtual_2020/poster_BJxI5gHKDr.html">talk (15 mins)</a> /  
                <a href="https://arxiv.org/abs/1701.05369">arXiv</a> / 
                <a href="https://senya-ashukha.github.io/projects/svdo_icml17/paper.txt" target="_blank">bibtex</a> / 
                code (<a href="https://github.com/bayesgroup/variational-dropout-sparsifies-dnn">theano</a>,
                <a href="https://github.com/google-research/google-research/tree/master/state_of_sparsity/layers/variational_dropout" target="_blank">tf by GoogleAI</a>,
                <a href="https://colab.research.google.com/github/bayesgroup/deepbayes-2019/blob/master/seminars/day6/SparseVD-solution.ipynb" target="_blank">colab pytorch</a>)
                  <div id="contact2" style="display: none;"> 
                    <br>
                    <br>
                    <b>Retrospective</b>: 
                    <ul>
                    <li> SparsesVD works in practice and it was used for network sparsification in leading IT companies. However, future studies showed that careful usage of pruning-based methods <a href="https://arxiv.org/abs/1902.09574">can produce</a> better results. </li>
                    <li> Training of deep models with noise is known to be hard and unstable. That is less the case with SparseVD. All variances are initialized with small values and did not change much during training. Using small variances does not hurt the performance, thus SparseVD might be considered as a fancy regulariser with (almost) no noise. </li>
                    <li> The sparse solution is just a local optimum, as better values of ELBO <a href="https://openreview.net/forum?id=B1GAUs0cKQ">can be achieved</a> with a <ins>less</ins> flexible variational posterior q(w_ij)=N(w_ij | 0, œÉ_ij).</li>
                   </ul>
                      </p>
                  </div>
              <p></p>
              <p>
              We show that variational dropout trains highly sparsified deep neural networks, while a pattern of sparsity is learned jointly with weights during training.</p>
            </td>
          </tr> 

          <tr>
            <td colspan="2" style="padding: 0;">
                <button type="button" class="toggle-button" id="toggleOlderProjects">
                  More projects ...
                </button>
            </td>
          </tr>
        </tbody>
        
        <tbody class="collapsible-content" id="olderProjects">
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='projects/pitfalls_unc_ens_iclr20/pic.png' width="160px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle" bgcolor="#ffffff">
              <a href="https://openreview.net/forum?id=BJxI5gHKDr">
                <papertitle>Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning </papertitle>
              </a>
              <br>
              <strong>Arsenii Ashukha*</strong>,
              <a href="https://scholar.google.ru/citations?user=5LXTi40AAAAJ&hl=en">Alexander Lyzhov*</a>,
              <a href="https://scholar.google.com/citations?user=tJ6JXRYAAAAJ&hl=en">Dmitry Molchanov*</a>,
              <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
              <br>
                <em>ICLR</em>, 2020  
              <br>
              <a href="https://senya-ashukha.github.io/pitfalls-uncertainty&ensembling">blog post</a> / 
                <a href="https://iclr.cc/virtual_2020/poster_BJxI5gHKDr.html">poster video (5mins)</a> / 
                <a href="https://github.com/bayesgroup/pytorch-ensembles">code</a> / 
                <a href="https://arxiv.org/abs/2002.06470">arXiv</a> / 
                <a href="https://senya-ashukha.github.io/projects/pitfalls_unc_ens_iclr20/paper.txt" target="_blank">bibtex</a>
              <p></p>
              <p>
            The work shows that i) a simple ensemble of independently trained networks performs significantly better than recent techniques ii) a simple test-time augmentation applied to a conventional network outperforms low-parameters ensembles (e.g. Dropout) and also improves all ensembles for free iii) a comparison of the uncertainty estimation ability of algorithms is often done incorrectly in the literature. </p>  
            </td>
          </tr> 
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:10px;width:25%;vertical-align:middle">
                <img src='projects/gps_uai20/gps.png' width="170px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
              <a href="http://proceedings.mlr.press/v124/lyzhov20a.html">
                <papertitle>Greedy Policy Search: A Simple Baseline for Learnable Test-Time Augmentation</papertitle>
              </a>
              <br>
              <strong>Arsenii Ashukha*</strong>,
              <a href="https://scholar.google.com/citations?user=tJ6JXRYAAAAJ&hl=en">Dmitry Molchanov*</a>,
              <a href="https://scholar.google.ru/citations?user=5LXTi40AAAAJ&hl=en">Alexander Lyzhov*</a>,
              <a href="">Yuliya Molchanova*</a>,
              <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
              <br>
                <em>UAI</em>, 2020  
              <br>
                <a href="https://github.com/bayesgroup/gps-augment">code</a> / 
                <a href="https://arxiv.org/abs/2002.09103">arXiv</a> / 
               <a href="https://senya-ashukha.github.io/projects/gps_uai20/gps_uai20_slides.pdf" target="_blank">slides</a> /
                <a href="https://senya-ashukha.github.io/projects/gps_uai20/paper.txt" target="_blank">bibtex</a>
              <p></p>
              <p>
            We introduce greedy policy search (GPS), a simple but high-performing method for learning a policy of test-time augmentation.    
              </td>
            </tr>
            <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='projects/dwp_iclr19/dwp.png' width="160px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=ByGuynAct7">
                <papertitle>The Deep Weight Prior</papertitle>
              </a>
              <br>
              <strong>Arsenii Ashukha*</strong>,
              <a href="https://scholar.google.com/citations?user=XriU_R8AAAAJ&hl=en">Andrei Atanov*</a>,
              <a href="https://scholar.google.com/citations?user=q69zIO0AAAAJ&hl=en">Kirill Struminsky</a>,
              <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>,
              <a href="https://staff.fnwi.uva.nl/m.welling/">Max Welling</a>
              <br>
                <em>ICLR</em>, 2019  
              <br>
                <a href="https://github.com/bayesgroup/deep-weight-prior">code</a> /
                <a href="https://arxiv.org/abs/1810.06943">arXiv</a> / 
                <a href="https://senya-ashukha.github.io/projects/dwp_iclr19/paper.txt" target="_blank">bibtex</a> 
              <p></p>
              <p>
                The <i>deep weight prior</i> is the generative model for kernels of convolutional neural networks, that acts as a prior distribution while training on new datasets.</p>
            </td>
          </tr> 

          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='projects/vn-iclr19/vn.png' width="160px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=B1GAUs0cKQ">
                <papertitle>Variance Networks: When Expectation Does Not Meet Your Expectations</papertitle>
              </a>
              <br>
              <strong>Arsenii Ashukha*</strong>,
              <a href="https://scholar.google.ru/citations?user=eOttYWgAAAAJ&hl=en">Kirill Neklyudov*</a>,
              <a href="https://scholar.google.com/citations?user=tJ6JXRYAAAAJ&hl=en">Dmitry Molchanov*</a>,
              <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
              <br>
                <em>ICLR</em>, 2019  
              <br>
                <a href="https://github.com/da-molchanov/variance-networks">code</a> /
                <a href="https://arxiv.org/abs/1803.03764">arXiv</a> / 
                <a href="https://senya-ashukha.github.io/projects/vn-iclr19/paper.txt" target="_blank">bibtex</a> 
              <p></p>
              <p>
                It is possible to learn a zero-centered Gaussian distribution over the weights of a neural network by learning only variances, and it works surprisingly well.</p>
            </td>
          </tr> 
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='projects/nfssl_innf19/nfssl.png' width="160px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
              <a href="https://invertibleworkshop.github.io/INNF_2019/accepted_papers/pdfs/INNF_2019_paper_20.pdf">
                <papertitle>Semi-Conditional Normalizing Flows for Semi-Supervised Learning</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=XriU_R8AAAAJ&hl=en">Andrei Atanov</a>,        
              <a href="https://alexandravolokhova.github.io/">Alexandra Volokhova</a>,
              <strong>Arsenii Ashukha</strong>,
              <a href="https://isosnovik.xyz/">Ivan Sosnovik</a>,
              <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
              <br>
                <em>INNF Workshop at ICML</em>, 2019  
              <br>
                <a href="https://github.com/AndrewAtanov/semi-supervised-flow-pytorch">code</a> /
                <a href="https://arxiv.org/abs/1905.00505">arXiv</a> / 
                <a href="https://senya-ashukha.github.io/projects/nfssl_innf19/paper.txt" target="_blank">bibtex</a> 
              <p></p>
              <p>We employ semi-conditional normalizing flow architecture that allows efficiently trains normalizing flows when only few labeled data points are available.</p>
            </td>
          </tr> 

            <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='projects/dyn_nips19/dyn_aae.png' width="160px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
              <a href="http://bayesiandeeplearning.org/2019/papers/102.pdf">
                <papertitle>Unsupervised Domain Adaptation with SharedLatent Dynamics for Reinforcement Learning</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=XriU_R8AAAAJ&hl=en">Evgenii Nikishin</a>,        
              <strong>Arsenii Ashukha</strong>,
              <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
              <br>
                <em>BLD Workshop at NeurIPS</em>, 2019  
              <br>
                <a href="https://github.com/evgenii-nikishin/dyn_aae">code</a> /
                <a href="https://evgenii-nikishin.github.io/data/dyn_aae_poster.pdf">poster</a> 
              <p></p>
              <p>Domain adaptation via learning shared dynamics in a latent space with adversarial matching of latent states.</p>
            </td>
          </tr> 
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='projects/sbn_iclrw18/sbn.png' width="160px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=r1yXEdkvz">
                <papertitle>Uncertainty Estimation via Stochastic Batch Normalization</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=XriU_R8AAAAJ&hl=en">Andrei Atanov</a>,
              <strong>Arsenii Ashukha</strong>,
              <a href="https://scholar.google.com/citations?user=tJ6JXRYAAAAJ&hl=en">Dmitry Molchanov</a>,
              <a href="https://scholar.google.ru/citations?user=eOttYWgAAAAJ&hl=en">Kirill Neklyudov</a>,
              <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
              <br>
                <em>Joint Workshop Track at ICLR</em>, 2018  
              <br>
                <a href="https://github.com/AndrewAtanov/stochastic-batch-normalization">code</a> /
                <a href="https://arxiv.org/abs/1802.04893">arXiv</a>
              <p></p>
              <p>Inference-time stochastic batch normalization improves the performance of uncertainty estimation of ensembles.</p>
            </td>
          </tr> 

            <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='projects/sbp_neurips17/sbp.png' width="160px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
              <a href="http://papers.nips.cc/paper/7254-structured-bayesian-pruning-via-log-normal-multiplicative-noise">
                <papertitle>Structured Bayesian Pruning via Log-Normal Multiplicative Noise</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.ru/citations?user=eOttYWgAAAAJ&hl=en">Kirill Neklyudov</a>,
              <a href="https://scholar.google.com/citations?user=tJ6JXRYAAAAJ&hl=en">Dmitry Molchanov</a>,
              <strong>Arsenii Ashukha</strong>,
              <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
              <br>
                <em>NeurIPS</em>, 2017  
              <br>
               <a href="https://github.com/necludov/group-sparsity-sbp">code</a> / 
                <a href="https://arxiv.org/abs/1705.07283">arXiv</a> / 
                <a href="https://senya-ashukha.github.io/projects/sbp_neurips17/paper.txt" target="_blank">bibtex</a> / 
                <a href="https://bayesgroup.github.io/pdf/sbp-poster.pdf">poster</a> 
              <p></p>
              <p>
              The model allows to sparsify a DNN with an arbitrary pattern of spasticity e.g., neurons or convolutional filters. 
              
            </td>
          </tr>
        </tbody> </table>
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <heading>Open source implementations</heading>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p align="left">
                <ul>
                <li><a href="https://github.com/advimman/lama">LaMa Inpainting</a></li>
                <li><a href="https://github.com/senya-ashukha/simple-gradient-boosting">Gradient Boosting</a></li>
                <li><a href="https://github.com/senya-ashukha/real-nvp-pytorch">Real NVP</a></li>
                <li><a href="https://github.com/senya-ashukha/quantile-regression-dqn-pytorch">Quantile Regression DQN (Distributional RL)</a></li>
                <li><a href="https://github.com/senya-ashukha/simple-equivariant-gnn">Equivariant GNN</a></li>
                <li><a href="https://github.com/AndrewAtanov/simclr-pytorch">Multi-gpu SimCLRv1</a></li>
                <li><a href="https://github.com/bayesgroup/pytorch-ensembles">Ensembles (Deep ensembles, Snapshot ensembles, cSGLD, FGE, etc.)</li>
              <ul>
              </p>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p align="right" class="container">
                The webpage template was borrowed from <a href="https://people.eecs.berkeley.edu/~barron/">Jon Barron</a>.
                <br>
                * denotes joint first co-authorship.
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

  <script>
    document.getElementById('toggleOlderProjects').addEventListener('click', function() {
      var content = document.getElementById('olderProjects');
      if (content.style.display === 'none' || content.style.display === '') {
        content.style.display = 'table-row-group'; // Use 'table-row-group' for tbody
        this.textContent = 'Less Project ...';
      } else {
        content.style.display = 'none';
        this.textContent = 'More Projects...';
      }
    });
  </script>

</body>

</html>
